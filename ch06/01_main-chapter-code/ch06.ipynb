{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# Chapter 6: Finetuning for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.3\n",
      "numpy version: 2.0.2\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.0\n",
      "tensorflow version: 2.19.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # Plotting library\n",
    "        \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "        \"tiktoken\",    # Tokenizer\n",
    "        \"torch\",       # Deep learning library\n",
    "        \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "        \"pandas\"       # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/chapter-overview.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 Different categories of finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
   "metadata": {
    "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
   },
   "source": [
    "- No code in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {},
   "source": [
    "- The most common ways to finetune language models are instruction-finetuning and classification finetuning\n",
    "- Instruction-finetuning, depicted below, is the topic of the next chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/instructions.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {},
   "source": [
    "- Classification finetuning, the topic of this chapter, is a procedure you may already be familiar with if you have a background in machine learning -- it's similar to training a convolutional network to classify handwritten digits, for example\n",
    "- In classification finetuning, we have a specific number of class labels (for example, \"spam\" and \"not spam\") that the model can output\n",
    "- A classification finetuned model can only predict classes it has seen during training (for example, \"spam\" or \"not spam\"), whereas an instruction-finetuned model can usually perform many tasks\n",
    "- We can think of a classification-finetuned model as a very specialized model; in practice, it is much easier to create a specialized model than a generalist model that performs well on many different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/spam-non-spam.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-1.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- This section prepares the dataset we use for classification finetuning\n",
    "- We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them\n",
    "- First, we download and unzip the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e62adc",
   "metadata": {},
   "source": [
    "下载和解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "424e4423-f623-443c-ab9e-656f9e867559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- The dataset is saved as a tab-separated text file, which we can load into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
    "- (Next to undersampling, there are several other ways to deal with class balances, but they are out of the scope of a book on LLMs; you can find examples and more information in the [`imbalanced-learn` user guide](https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e03fa8",
   "metadata": {},
   "source": [
    "创建一个平衡的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "396dc415-cb71-4a88-e85d-d88201c6d73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \"\"\"创建平衡数据集（通过下采样ham类别）\n",
    "    Args:\n",
    "        df: 原始数据集DataFrame，需包含'Label'列\n",
    "    Returns:\n",
    "        balanced_df: 平衡后的数据集，包含相同数量的spam和ham样本\n",
    "    \"\"\"\n",
    "    # 统计spam样本数量作为基准\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # 使用固定随机种子保证可重复采样\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # 合并下采样后的ham样本与全部spam样本\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f342c78",
   "metadata": {},
   "source": [
    "现在，将“string”类别标签 \"ham\" 和 \"spam\" 分别转换为整数类别标签 0 和 1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- Let's now define a function that randomly divides the dataset into training, validation, and test subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd5452",
   "metadata": {},
   "source": [
    "接下来，如代码清单 6-3 所示，创建一个 random_split 函数，将数据集分成 3 部分：70% 用于训练，10% 用于验证，20% 用于测试。​（这些比例在机器学习中很常见，用于训练、调整和评估模型。​）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    \"\"\"数据集随机分割函数\n",
    "    Args:\n",
    "        df: 要分割的原始DataFrame\n",
    "        train_frac: 训练集比例 (0-1)\n",
    "        validation_frac: 验证集比例 (0-1)\n",
    "    Returns:\n",
    "        tuple: (训练集, 验证集, 测试集) 三元组\n",
    "    \"\"\"\n",
    "    # 打乱数据集并重置索引（固定随机种子保证可重复性）\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # 计算各分割点的索引位置\n",
    "    train_end = int(len(df) * train_frac)          # 训练集结束位置\n",
    "    validation_end = train_end + int(len(df) * validation_frac)  # 验证集结束位置\n",
    "\n",
    "    # 切片分割数据集\n",
    "    train_df = df[:train_end]              # 训练数据集\n",
    "    validation_df = df[train_end:validation_end]  # 验证数据集\n",
    "    test_df = df[validation_end:]          # 测试数据集（剩余部分）\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {},
   "source": [
    "## 6.3 Creating data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- Note that the text messages have different lengths; if we want to combine multiple training examples in a batch, we have to either\n",
    "  1. truncate all messages to the length of the shortest message in the dataset or batch\n",
    "  2. pad all messages to the length of the longest message in the dataset or batch\n",
    "\n",
    "- We choose option 2 and pad all messages to the longest message in the dataset\n",
    "- For that, we use `<|endoftext|>` as a padding token, as discussed in chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/pad-input-sequences.webp?123\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898153e",
   "metadata": {},
   "source": [
    "然而，基于性能与效率的考虑，与其直接将字符串 \"<|endoftext|>\" 附加到每条文本消息中，不如将与 \"<|endoftext|>\" 对应的词元 ID 添加到编码的文本消息中，如图6-6 所示。50256 是填充词元 \"<|endoftext|>\"的词元 ID。我们可以使用之前用过的 tiktoken包中的 GPT-2 分词器来核对词元 ID 是否正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- The `SpamDataset` class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac0172",
   "metadata": {},
   "source": [
    "构建一个 Pytorch Dataset 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        \"\"\"数据集初始化方法\n",
    "        Args:\n",
    "            csv_file: 数据文件路径\n",
    "            tokenizer: 文本分词器\n",
    "            max_length: 最大序列长度（None则自动计算最长长度）\n",
    "            pad_token_id: 填充token的ID\n",
    "        \"\"\"\n",
    "        # 读取原始CSV数据文件\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        # 将文本转换为token ID序列列表\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        # 处理序列最大长度逻辑\n",
    "        if max_length is None:\n",
    "            # 自动计算最长序列长度\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            # 使用指定的最大长度并截断超长序列\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        # 对所有序列进行填充至统一长度\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        # Note: A more pythonic version to implement this method\n",
    "        # is the following, which is also used in the next chapter:\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fbbb16",
   "metadata": {},
   "source": [
    "SpamDataset 类从我们之前创建的 CSV 文件中加载数据，使用 tiktoken中的 GPT-2 分词器对文本进行分词，并将序列填充或截断到由最长序列或预定义的最大长度确定的统一长度。确保每个输入张量的大小相同对于接下来实现数据批处理是必要的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63485595",
   "metadata": {},
   "source": [
    "代码输出的是 120，表明最长序列不超过120 个词元，这是文本消息的常见长度。鉴于模型的上下文长度限制，它可以处理最多 1024 个词元的序列。如果你的数据集中包含更长的文本，可以在创建训练数据集时将 max_length=1024 传递进去，以确保数据不会超出模型支持的输入（上下文）长度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {},
   "source": [
    "- We also pad the validation and test set to the longest training sequence\n",
    "- Note that validation and test set samples that are longer than the longest training example are being truncated via `encoded_text[:self.max_length]` in the `SpamDataset` code\n",
    "- This behavior is entirely optional, and it would also work well if we set `max_length=None` in both the validation and test set cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {},
   "source": [
    "- Next, we use the dataset to instantiate the data loaders, which is similar to creating the data loaders in previous chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/batch.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {},
   "source": [
    "- As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad093581",
   "metadata": {},
   "source": [
    "为了确保数据加载器正常工作并返回预期大小的批次，可以迭代训练加载器，并打印最后一个批次的张量维度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {},
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {},
   "source": [
    "- In this section, we initialize the pretrained model we worked with in the previous chapter\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-2.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c8e1c",
   "metadata": {},
   "source": [
    "为了开始模型准备过程，我们使用与预训练未标记数据时相同的配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a2ae8",
   "metadata": {},
   "source": [
    "加载预训练的 GPT 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "7091e401-8442-4f47-a1d9-ecb42a1ef930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {},
   "source": [
    "- To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18485a39",
   "metadata": {},
   "source": [
    "在将模型权重加载到 GPTModel 后，重用第4章和第5章中的文本生成工具函数，以确保模型生成连贯的文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import (\n",
    "#    generate_text_simple,\n",
    "#    text_to_token_ids,\n",
    "#    token_ids_to_text\n",
    "# )\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {},
   "source": [
    "- Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6992ef",
   "metadata": {},
   "source": [
    "在开始将模型微调为垃圾消息分类器之前，让我们输入指令信息，看看模型是否已经能够分类垃圾消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {},
   "source": [
    "- As we can see, the model is not very good at following instructions\n",
    "- This is expected, since it has only been pretrained and not instruction-finetuned (instruction finetuning will be covered in the next chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 Adding a classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/lm-head.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {},
   "source": [
    "- In this section, we are modifying the pretrained LLM to make it ready for classification finetuning\n",
    "- Let's take a look at the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d8f7a01-b7c0-48d4-b1e7-8c12cc7ad932",
    "outputId": "b6a5b9b5-a92f-498f-d7cb-b58dd99e4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {},
   "source": [
    "- Above, we can see the architecture we implemented in chapter 4 neatly laid out\n",
    "- The goal is to replace and finetune the output layer\n",
    "- To achieve this, we first freeze the model, meaning that we make all layers non-trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638e7a44",
   "metadata": {},
   "source": [
    "为了使模型准备好进行分类微调，我们首先冻结模型，即将所有层设为不可训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {},
   "source": [
    "- Then, we replace the output layer (`model.out_head`), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)\n",
    "- Since we finetune the model for binary classification (predicting 2 classes, \"spam\" and \"not spam\"), we can replace the output layer as shown below, which will be trainable by default\n",
    "- Note that we use `BASE_CONFIG[\"emb_dim\"]` (which is equal to 768 in the `\"gpt2-small (124M)\"` model) to keep the code below more general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfce037",
   "metadata": {},
   "source": [
    "替换输出层(model.out_head)，该层原本是将输入映射为 50 257 维，即词汇表的大小（参见图6-9）​。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子保证实验可重复性\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 定义分类任务类别数（二分类问题）\n",
    "num_classes = 2\n",
    "\n",
    "# 替换模型输出层为线性分类头，适配当前分类任务\n",
    "# in_features: 输入维度来自基础配置的嵌入维度\n",
    "# out_features: 输出维度对应分类类别数\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {},
   "source": [
    "- Technically, it's sufficient to only train the output layer\n",
    "- However, as I found in [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models), experiments show that finetuning additional layers can noticeably improve the performance\n",
    "- So, we are also making the last transformer block and the final `LayerNorm` module connecting the last transformer block to the output layer trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f27b22",
   "metadata": {},
   "source": [
    "GPT 模型包含 12 个重复的 Transformer 块。除了输出层，我们还将最终层归一化和最后一个 Transformer 块设置为可训练。其余 11 个 Transformer 块和嵌入层则保持为不可训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/trainable.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a82cfbd",
   "metadata": {},
   "source": [
    "为了使最终层归一化和最后一个 Transformer 块可训练，我们将它们各自的requires_grad 设置为 True。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {},
   "source": [
    "- We can still use this model similar to before in previous chapters\n",
    "- For example, let's feed it some text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "27e041b1-d731-48a1-cf60-f22d4565304e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# 将文本编码为token ID序列\n",
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "\n",
    "# 转换为张量并添加批次维度（batch_size=1）\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "\n",
    "# 打印输入张量内容\n",
    "print(\"Inputs:\", inputs)\n",
    "\n",
    "# 打印输入维度信息（批次大小, 序列长度）\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {},
   "source": [
    "- What's different compared to previous chapters is that it now has two output dimensions instead of 50,257"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ff5db",
   "metadata": {},
   "source": [
    "接下来，可以像往常一样将编码后的词元 ID 传递给模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "9cae7448-253d-4776-973e-0af190b06354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {},
   "source": [
    "- As discussed in previous chapters, for each input token, there's one output vector\n",
    "- Since we fed the model a text sample with 4 input tokens, the output consists of 4 2-dimensional output vectors above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/input-and-output.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {},
   "source": [
    "- In chapter 3, we discussed the attention mechanism, which connects each input token to each other input token\n",
    "- In chapter 3, we then also introduced the causal attention mask that is used in GPT-like models; this causal mask lets a current token only attend to the current and previous token positions\n",
    "- Based on this causal attention mechanism, the 4th (last) token contains the most information among all tokens because it's the only token that includes information about all other tokens\n",
    "- Hence, we are particularly interested in this last token, which we will finetune for the spam classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880186d",
   "metadata": {},
   "source": [
    "需要注意的是，我们的目标是微调此模型，使其返回一个类别标签，以指出输入是“垃圾消息”还是“非垃圾消息”​。因此，我们不需要微调所有 4 个输出行，只需关注一个输出词元，特别是最后一个输出词元对应的行即可，如图6-11 所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "e79eb155-fa1f-46ed-ff8c-d828c3a3fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/attention-mask.webp\" width=200px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da51ff",
   "metadata": {},
   "source": [
    "根据图6-12中的因果注意力掩码设置，序列中的最后一个词元累积了最多的信息，因为它是唯一一个可以访问之前所有数据的词元。因此，在垃圾消息分类任务中，我们在微调过程中会关注这个最后的词元。现在我们准备将最后的词元转换为类别标签进行预测，并计算模型的初始预测准确率。随后，我们将对模型进行垃圾消息分类任务的微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {},
   "source": [
    "## 6.6 Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-3.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {},
   "source": [
    "- Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d643d9",
   "metadata": {},
   "source": [
    "在实现评估工具之前，让我们简要讨论一下如何将模型输出转换为类别标签预测。之前我们通过将 50 257 个输出转换为概率（利用 softmax 函数）​，然后返回最高概率的位置（利用 argmax 函数）​，来计算大语言模型生成的下一个词元的词元 ID。在这里，我们采取相同的方法来计算模型对于给定输入是预测为“垃圾消息”还是“非垃圾消息”​，如图6-14 所示。唯一的区别是我们处理的是 2 维而不是 50 257 维的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/class-argmax.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63da461",
   "metadata": {},
   "source": [
    "对应于最后一个词元的模型输出被转换为每个输入文本的概率分数。通过查找最高概率分数的索引位置获得类别标签。由于模型尚未训练，因此它错误地预测了垃圾消息标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b55f3",
   "metadata": {},
   "source": [
    "让我们通过一个具体的例子来考虑最后一个词元输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we convert the outputs (logits) into probability scores via the `softmax` function and then obtain the index position of the largest probability value via the `argmax` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e82b56",
   "metadata": {},
   "source": [
    "我们可以获得以下类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c95e92",
   "metadata": {},
   "source": [
    "在这种情况下，代码返回 1，意味着模型预测输入文本为“垃圾消息”​。在这里使用softmax 函数是可选的，因为最大的输出直接对应于最高的概率分数。因此，可以简化代码，不使用 softmax："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {},
   "source": [
    "- Note that the softmax function is optional here, as explained in chapter 5, because the largest outputs correspond to the largest probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {},
   "source": [
    "- We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset\n",
    "- To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f6e3b",
   "metadata": {},
   "source": [
    "为了确定分类准确率，我们将基于 argmax的预测代码应用于数据集中的所有示例，并通过定义 calc_accuracy_loader 函数计算正确预测的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):#计算整体准确率\n",
    "    # 设置模型为评估模式\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    # 处理批次数量限制\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "        \n",
    "    # 遍历数据加载器\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            # 将数据转移到指定设备\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            # 禁用梯度计算以加速推理\n",
    "            with torch.no_grad():\n",
    "                # 获取最后一个输出位置的logits（适用于生成任务）\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            # 获取预测结果（最大logit对应的索引）\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # 更新统计计数\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    # 返回整体准确率\n",
    "    return correct_predictions / num_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {},
   "source": [
    "- Let's apply the function to calculate the classification accuracies for the different datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f133c",
   "metadata": {},
   "source": [
    "- 接下来，使用该函数来确定各个数据集的分类准确率。我们用 10 个批次的数据进行估计以提高效率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#print(f\"Running on {device} device.\")\n",
    "\n",
    "# 将模型转移到指定设备（GPU/CPU）\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "# 设置随机种子保证实验可复现性（影响数据加载器的洗牌操作）\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "# 计算各数据集的预测准确率（限制10个批次以加快评估速度）\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "# 格式化输出准确率结果（保留两位小数）\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")  # 训练集准确率\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")  # 验证集准确率\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")       # 测试集准确率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4679f6b",
   "metadata": {},
   "source": [
    "- 可以看到，预测准确率接近随机预测，在这种情况下为 50%。为了提高预测准确率，需要对模型进行微调。\n",
    "- 然而，在开始微调模型之前，需要定义训练期间要优化的损失函数。我们的目标是最大化模型的垃圾消息分类准确率，这意味着前面的代码应该输出正确的类别标签：0 表示非垃圾消息，1 表示垃圾消息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {},
   "source": [
    "- As we can see, the prediction accuracies are not very good, since we haven't finetuned the model, yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {},
   "source": [
    "- Before we can start finetuning (/training), we first have to define the loss function we want to optimize during training\n",
    "- The goal is to maximize the spam classification accuracy of the model; however, classification accuracy is not a differentiable function\n",
    "- Hence, instead, we minimize the cross-entropy loss as a proxy for maximizing the classification accuracy (you can learn more about this topic in lecture 8 of my freely available [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) class)\n",
    "\n",
    "- The `calc_loss_batch` function is the same here as in chapter 5, except that we are only interested in optimizing the last token `model(input_batch)[:, -1, :]` instead of all tokens `model(input_batch)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dfab64",
   "metadata": {},
   "source": [
    "由于分类准确率不是一个可微分的函数，这里我们使用交叉熵损失作为替代来最大化准确率。因此，calc_loss_batch 函数保持不变，唯一的调整是专注于优化最后一个词元(model(input_batch)[:, -1, :])而不是所有词元(model(input_batch))。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    # 将数据转移到指定设备（GPU/CPU）\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    \n",
    "    # 获取模型输出的最后一个token的logits（适用于生成任务）\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    \n",
    "    # 计算交叉熵损失（自动处理logits的softmax转换）\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "The `calc_loss_loader` is exactly the same as in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {},
   "source": [
    "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {},
   "source": [
    "- In the next section, we train the model to improve the loss values and consequently the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {},
   "source": [
    "- In this section, we define and use the training function to improve the classification accuracy of the model\n",
    "- The `train_classifier_simple` function below is practically the same as the `train_model_simple` function we used for pretraining the model in chapter 5\n",
    "- The only two differences are that we now \n",
    "  1. track the number of training examples seen (`examples_seen`) instead of the number of tokens seen\n",
    "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/training-loop.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # 初始化跟踪指标：训练/验证损失、准确率、已处理样本数\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1  # global_step从-1开始以包含第0步评估\n",
    "\n",
    "    # 主训练循环（每个epoch）\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 设置模型为训练模式（启用dropout等）\n",
    "\n",
    "        # 遍历训练数据加载器\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # 梯度归零 -> 前向计算 -> 反向传播 -> 参数更新\n",
    "            optimizer.zero_grad() # 清空上一步的梯度\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # 计算梯度\n",
    "            optimizer.step() # 更新模型参数\n",
    "            \n",
    "            # 更新统计指标（按样本数计数）\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1  # 每次参数更新计为一步\n",
    "\n",
    "            # 定期评估模型（频率由eval_freq控制）\n",
    "            if global_step % eval_freq == 0:\n",
    "                # 在训练集和验证集上评估损失\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                # 打印当前训练进度（格式化输出损失值）\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # 每个epoch结束后计算准确率\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        # 格式化输出准确率结果（保留两位小数）\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        # 记录准确率指标\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    # 返回所有跟踪指标（用于后续分析/可视化）\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {},
   "source": [
    "- The `evaluate_model` function used in the `train_classifier_simple` is the same as the one we used in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    # 设置模型为评估模式（禁用dropout等训练专用层）\n",
    "    model.eval()\n",
    "    # 禁用梯度计算以加速评估过程\n",
    "    with torch.no_grad():\n",
    "        # 计算训练集和验证集的平均损失（限制评估批次数量）\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    # 恢复模型为训练模式（确保后续训练正常进行）\n",
    "    model.train()\n",
    "    # 返回双损失值（训练损失，验证损失）\n",
    "    return train_loss, val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {},
   "source": [
    "- The training takes about 5 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.676, Val loss 0.672\n",
      "Ep 1 (Step 000050): Train loss 0.540, Val loss 0.581\n",
      "Ep 1 (Step 000100): Train loss 0.407, Val loss 0.470\n",
      "Training accuracy: 87.50% | Validation accuracy: 80.00%\n",
      "Ep 2 (Step 000150): Train loss 0.673, Val loss 0.472\n",
      "Ep 2 (Step 000200): Train loss 0.400, Val loss 0.360\n",
      "Ep 2 (Step 000250): Train loss 0.440, Val loss 0.317\n",
      "Training accuracy: 82.50% | Validation accuracy: 82.50%\n",
      "Ep 3 (Step 000300): Train loss 0.324, Val loss 0.316\n",
      "Ep 3 (Step 000350): Train loss 0.343, Val loss 0.300\n",
      "Training accuracy: 90.00% | Validation accuracy: 85.00%\n",
      "Ep 4 (Step 000400): Train loss 0.207, Val loss 0.257\n",
      "Ep 4 (Step 000450): Train loss 0.128, Val loss 0.117\n",
      "Ep 4 (Step 000500): Train loss 0.138, Val loss 0.138\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 5 (Step 000550): Train loss 0.179, Val loss 0.141\n",
      "Ep 5 (Step 000600): Train loss 0.043, Val loss 0.038\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Training completed in 8.90 minutes.\n"
     ]
    }
   ],
   "source": [
    "# 导入时间模块用于计算训练时长\n",
    "import time\n",
    "\n",
    "# 记录训练开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 设置随机种子保证实验可复现性\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 初始化AdamW优化器（带权重衰减防止过拟合）\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "# 配置训练参数\n",
    "num_epochs = 5  # 总训练轮数\n",
    "# 启动模型训练流程（每50步评估一次，每次评估使用5个批次）\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "# 计算并输出总训练时间\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60  # 转换为分钟\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")  # 保留两位小数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we use matplotlib to plot the loss function for the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWjBJREFUeJztnQdUFGcXhl96k46CiAjYRcWCYo2x9xZbjAV71MSYqCn+SWyJ0SRGjdHYa+w99l5ix967olhALCC97n/uN+6yi4AgZWd373POHGZmZ2e+Hdd9597vFiOFQqEAwzAMwzCyxFjbA2AYhmEYJnNYqBmGYRhGxrBQMwzDMIyMYaFmGIZhGBnDQs0wDMMwMoaFmmEYhmFkDAs1wzAMw8gYFmqGYRiGkTEs1AzDMAwjY1ioGYbJFh9++CG+/PJLbQ+DYQwOFmqGKSD69OkDIyOjt5YWLVpoe2gMw8gYU20PgGEMCRLlxYsXa+yzsLDQ2ngYhpE/bFEzTAFCouzm5qaxODo6itcOHToEc3NzHDlyRHX8b7/9hiJFiiAsLExs79q1C/Xq1YODgwOcnZ3Rpk0b3L17V3V8cHCwsNLXrl2L+vXrw8rKCjVq1MCtW7dw+vRp+Pv7o1ChQmjZsiXCw8M1rP0OHTpg/PjxKFy4MOzs7DB48GAkJiZm+lkSEhIwatQoFCtWDDY2NggICBCfQcmDBw/Qtm1b8fnodV9fX+zYsSPT8/39998oXbo0LC0t4erqis6dO6teS01NxaRJk+Dt7S0+k5+fH9avX6/x/itXrojPRZ+P3t+rVy88f/5cw3X/xRdf4JtvvoGTk5O49+PGjcvWvxvDaBMWaoaR2RwwCUxkZCTOnz+PH3/8EQsWLBDCQ8TExGDEiBE4c+YM9u/fD2NjY3Ts2FEImTpjx47FDz/8gHPnzsHU1BSffPKJEKg///xTPAjcuXMHY8aM0XgPne/69etCbFetWoWNGzcK4c6Mzz//HCdOnMDq1atx6dIldOnSRXgMbt++LV7/7LPPhJj/999/uHz5Mn799VchohlBn4dEdMKECbh586Z4IPnggw9Ur5NIL1u2DHPmzMHVq1fx1VdfoWfPnjh8+LB4PSIiAo0aNULVqlXFuej99HDTtWtXjessXbpUPDScOnVKPATR9fbu3ZvjfyuGKVCozSXDMPlPYGCgwsTERGFjY6OxTJw4UXVMQkKCokqVKoquXbsqKlSooBg4cGCW5wwPD6c2tYrLly+L7fv374vtBQsWqI5ZtWqV2Ld//37VvkmTJinKli2rMTYnJydFTEyMat/s2bMVhQoVUqSkpIjtBg0aKIYPHy7WHzx4ID7L48ePNcbTuHFjxejRo8V6pUqVFOPGjcvWvdmwYYPCzs5O8fr167dei4+PV1hbWyuOHz+usb9///6K7t27i/WffvpJ0axZM43XQ0JCxOe+efOmavz16tXTOKZGjRqKb7/9NltjZBhtwXPUDFOANGzYELNnz9bYR25YJeT6XrFiBSpXrowSJUpg2rRpGseStUqWMFmE5NZVWtIPHz5ExYoVVcfR+5UorfFKlSpp7Hv27JnGucmdbG1trdquXbs2oqOjERISIsaiDlnIKSkpKFOmjMZ+sqDJJU+QhTxkyBDs2bMHTZo0QadOnTTGpU7Tpk3FNXx8fIRVTgt5Cmg8ZP3HxsaKY9QhtzxZ0MTFixdx8ODBDC12mhpQjjP99YsWLfrWfWAYucFCzTAFCLldS5UqleUxx48fF39fvnwpFnqPEprzJUGbP38+3N3dhVCTQKefSzYzM1Ot05x1RvvSu8tzAgm4iYkJzp49K/6qoxTLAQMGoHnz5ti+fbsQa3Jf//HHHxg2bNhb57O1tRVuenK707H0MELzxzSvTtci6Dw0H55RIB4dQ/eG3OvpITHO6L7kxX1gmIKAhZphZARZfzT/SkK8Zs0aBAYGYt++fWIu+sWLF2L+ll6jQDHi6NGjeXZtskrj4uJEsBZx8uRJIbrFixd/61iyZMmiJmtUOZaMoPdSUBoto0ePFmPPSKgJmksny5sWmmOngLkDBw4IS5oEmbwGDRo0yPC91apVw4YNG+Dl5SXOwzD6BH+jGaYAIddwaGioxj4SFhcXFyF8FCBFVmjfvn2F+5fc1WSFfv311yJ6mtzK8+bNE1YiCdd3332XZ2Mjq7x///4iCI2ix0ksKWCMHhLSQ67kHj16oHfv3mJ8JNwURU4BaeRebt26tQiMoyhsOvbVq1fCNV2+fPkMr71t2zbcu3dPBJDR56TocLJ0y5YtK6xtii6nBxjaR1HvFGx37NgxEZ1ODzMUuEYPAd27d1dFdZPLnALdKBgvvdXPMLoECzXDFCAUjazuiiVIjG7cuIGJEyeKlCYSLYKOI1Em8WnWrJmYQybhoblfcnfT+2bMmCGixfOCxo0bi/QoEkt6oKDrZpW+RPngP//8M0aOHInHjx+Lh41atWqJlDGCHjxIQB89eiQElR480s+5KyHrmaLM6Xrx8fFiHBR5TildxE8//STSxsh9ToJOx5MV/b///U+8TtMAJNzffvutuFc0fpoioGtm9KDBMLqEEUWUaXsQDMNoF8qjphSnzZs3a3soDMOkgx81GYZhGEbGsFAzDMMwjIxh1zfDMAzDyBi2qBmGYRhGxrBQMwzDMIyMYaFmGIZhGBnDQp0LZs2aJSohUVs+avEXFBQEfYU6IFGJRspXpbKL6dN4KNSByj5S7i9VtqLqUsouSkqoHCYVyaCcWsqDpeIayvKQSqgLE1W6ontKVa2ow5EuQPm91E6SinNQW0pqGUlVxNSh/GDKK6aiJVTxi2pfK9tXKqEiJlQshGpc03mo0ElycrLGMVRmk3KIqVoXlSNdsmQJdAGqcU7FUOjfnxaqJb5z507V64Z+fzJi8uTJ4v8bFY9RwvcJIt+e7ov6Uq5cOf29R1prB6LjrF69WmFubq5YtGiR4urVq6LLkYODgyIsLEyhj+zYsUPx/fffKzZu3Cg6Em3atEnj9cmTJyvs7e0VmzdvVly8eFHRrl07hbe3tyIuLk51TIsWLRR+fn6KkydPKo4cOaIoVaqUqvsRERkZqXB1dVX06NFDceXKFdH1ycrKSjF37lyF3GnevLli8eLFYtwXLlxQtGrVSuHp6amIjo5WHTN48GBF8eLFRRerM2fOKGrVqqWoU6eO6vXk5GRFxYoVFU2aNFGcP39e3HMXFxdVNyri3r17opPUiBEjFNeuXVP89ddfoovVrl27FHJny5Ytiu3btytu3bolOlr973//U5iZmYl7Rhj6/UlPUFCQwsvLS1G5cmVV1zKC75NCMXbsWIWvr6/i6dOnqoU6yenrPWKhfk9q1qyp+Oyzz1Tb1ArQ3d1dtA/Ud9ILdWpqqsLNzU3x+++/q/ZFREQoLCwshNgS9EWn950+fVp1zM6dOxVGRkaqVol///23wtHRUbR6VEItCNXbMeoKz549E5/38OHDqvtBorRu3TrVMdevXxfHnDhxQmzTj4WxsbEiNDRUo9UktX9U3pNvvvlG/ECp061bN/GgoIvQvze15OT7o0lUVJSidOnSir1792q0F+X7lCbU9NCfEfp4j9j1/Z41kalrELl3lVCZQto+ceIEDI379++L+tXq98Pe3l5MByjvB/0ld7e/v7/qGDqe7hu1bFQeQ+UrqdWjEqp7TS5kqhWtS1AtavUWlvR9SUpK0rhH5Krz9PTUuEdU21vZllL5+V+/fo2rV6+qjlE/h/IYXfveUXlRKocaExMjXOB8fzQhty25ZdN/Fr5PadDUGk3FUWtUmlIjV7a+3iMW6veA+gDTD436PzJB2+kbLhgCys+c1f2gvzQPlL4ZBQmZ+jEZnUP9GroANY6gOcW6deuqekTT+OkBhB5WsrpH7/r8mR1DPzDU+UruUB9rmjOkOT/qqLVp0yZUqFCB748a9ABDLT8p7iE9fJ8kyAig+WKqnU+xD2QsUGxLVFSUXt4jbsrBMPlgDV25ciVPW1DqC9RI5MKFC8LjsH79etH56vDhw9oelmwICQnB8OHDsXfvXhFQyWQMdWVTQgGKJNzUhGXt2rWqNq36BFvU7wF1CaK2eemjCGnbzc0NhobyM2d1P+gv9S5WhyIsKRJc/ZiMzqF+DblDbSGp+xW1dPTw8FDtp/HTlAk1vsjqHr3r82d2DEVR68IPFFk6FD1bvXp1YTFSR7A///yT788byG1L/08o0pg8TrTQgwx1SaN1suj4Pr0NWc/UTpVam+rjd4mF+j1/bOiHhnrvqrs7aZvm2wwNb29v8aVWvx/kHqK5Z+X9oL/0H4d+iJQcOHBA3Dd6GlYeQ2lgNL+khCwLssKoR7GcoRg7Emly5dLnonuiDn1fzMzMNO4Rzb3TvJr6PSLXsPoDDX1++mEg97DyGPVzKI/R1e8d/ftTS0q+P2mtRukzktdBuVBcB83BKtf5Pr0NpXnevXtXpIfq5XepwMPX9Cg9i6KalyxZIiKaBw0aJNKz1KMI9QmKQqU0BlroazN16lSx/uDBA1V6Fn3+f//9V3Hp0iVF+/btM0zPqlq1quLUqVOKo0ePiqhW9fQsitak9KxevXqJlB26x5QeoQvpWUOGDBHpaYcOHdJIGYmNjdVIGaGUrQMHDoiUkdq1a4slfcpIs2bNRIoXpYEULlw4w5SRr7/+WkSyzpo1S2fSar777jsRBX///n3xHaFtivrfs2ePeN3Q709mqEd9E3yfFIqRI0eK/2v0XTp27JhIs6L0Ksq20Md7xEKdCyivjr4MlE9N6VqUH6yvHDx4UAh0+iUwMFCVovXjjz8KoaUHmMaNG4tcWXVevHghhLlQoUIiDaJv377iAUAdysGuV6+eOEexYsXEA4AukNG9oYVyq5XQQ8vQoUNFShL9AHTs2FGIuTrBwcGKli1bivxx+uGhH6SkpKS3/i2qVKkivnc+Pj4a15Az/fr1U5QoUUKMm34U6TuiFGnC0O9PdoWa75NCpEkVLVpUjJ1+J2j7zp07enuPuHsWwzAMw8gYnqNmGIZhGBnDQs0wDMMwMoaFmmEYhmFkDAs1wzAMw8gYFmqGYRiGkTEs1AzDMAwjY1iocwFVVKIG5vSXyRy+T++G79G74Xv0bvge6ec94jzqXEBlMqmdIzUYoNJzTMbwfXo3fI/eDd+jd8P3SD/vEVvUDMMwDCNjWKgZhmEYRsYYXD9qaq14/vx50S7O2Dh3zynUpJx4/PixcKcwGcP36d3wPXo3fI/eDd8j3blH1DmO2mZWrVpVtDDNCoOboz59+jRq1qyp7WEwDMMwDIKCglCjRo0sjzE4i5osaeXNod6lDMMwDFPQPH36VBiNSk3KCoMTaqW7m0Taw8ND28NhGIZhDBjjbEzBcjAZwzAMw8gYFmqGYRiGkTEs1AzDMAwjYwxujpphGCYrUlJSkJSUpO1hMDqOmZkZTExM8uRcLNS54GVMIjacfYQB9b1hZGSk7eEwDJMLKFM1NDQUERER2h4Koyc4ODjAzc0t1/rAQv2eJCSnoMuc47gbHoPElFR81rCUtodkULyOT8K2i0/Roao7rM35a8zkHqVIFylSBNbW1vzwzeTqoS82NhbPnj0T27lNBeZfuPfEwtQEvWt7IXj7FFjvX4ot9r+iXTVvbQ/LYBiz+Qo2X3iC609f46cOFbU9HEYP3N1KkXZ2dtb2cBg9wMrKSvwlsabvVW7c4BxMlgsCfc3wg/kq9DXdDc/NnXHu0iVtD8kgeBIRh62Xnor19WcfISI2UdtDYnQc5Zw0WdIMk1cov0+5jXlgoc4N9sVg1PUfxBoXQhXjO/De2AqPT2/V9qj0niXHg5GSKlW+jUtKwerTIdoeEqMnsLubkeP3iYU6lxiXbwWTwf/hrmkpOCIKRbf3QsyuCUBqiraHppdEJyRj1amHYr1VJTfxd9nxYCSnpGp5ZAzDMPkDC3UeYFGkJByHHcQW0+YwhgI2J/9AyrKPgJjn2h6a3rHmdAiiEpLhU9gGU7tWgUshczyJjMfuq2HaHhrD6A1eXl6YPn16to8/dOiQsB7zO2J+yZIlIpLa0GChziOc7O3gN2QxfjQahjiFOUyCD0Expz7w8JS2h6Y3kNW86Oh9sd6/njcszUzQI6CE2F50TNrPMIYEiWNWy7hx4967y+CgQYOyfXydOnVEkwl7e/v3uh6TNSzUeUgJZxt07DsSXVIm4m5qURhFPYFiSSvgxN8Ur6/t4ek8u66G4nFEHJxszNGpmtRQpUctT5ibGOPsg1e4EML5r4xhQeKoXMgCtrOz09g3atQojZSh5OTkbJ23cOHCOQqsMzc3z5N8YSZjWKjzmGqejvj843Zon/QztqXUglFqMrB7NLAuEIjnRu7vC/3IzD8iWc09a5UQ1jRRxNYSbf3cxfpitqoZA4PEUbmQNUtCqdy+ceMGbG1tsXPnTlSvXh0WFhY4evQo7t69i/bt24v2ioUKFRK9kPft25el65vOu2DBAnTs2FEIeOnSpbFly5ZMXd9KF/Xu3btRvnx5cZ0WLVqIhwcl9NDwxRdfiOMoJe7bb79FYGAgOnTokKN7MHv2bJQsWVI8LJQtWxb//POPxu8GeRU8PT3F53d3dxfXVPL333+Lz2JpaSnuR+fOnSFHWKjzgRYV3TCidXV8njQMY5ICkWpkBlzfCoRd1fbQdBaymC+GRMDc1Bi9aknubiV963qJv9svPUVoZLyWRsjoZdGKxGStLHTtvOK7777D5MmTcf36dVSuXBnR0dFo1aoV9u/fj/PnzwsBbdu2LR4+lII0M2P8+PHo2rUrLl26JN7fo0cPvHz5MtPjqeDHlClThHD+999/4vzqFv6vv/6KFStWYPHixTh27Bhev36NzZs35+izbdq0CcOHD8fIkSNx5coVfPrpp+jbty8OHjwoXt+wYQOmTZuGuXPn4vbt2+L8lSpVEq+dOXNGiPaECRNw8+ZN7Nq1Cx988AHkCBc8ySf61fPGo1dxWHSsOa4llcLv9YzgXaK2toels8w/ck/87VilGArbWmi8VrGYPQK8nXDq/kv8czIYXzcvp6VRMvoEpf5VGLNbK9e+NqF5nlXcIyFq2rSpatvJyQl+fn6q7Z9++kkIHlnIn3/+eabn6dOnD7p37y7Wf/nlF8yYMQNBQUFC6DOCcofnzJkjrF2Czk1jUfLXX39h9OjRwkonZs6ciR07duTos02ZMkWMa+jQoWJ7xIgROHnypNjfsGFD8XBA3oUmTZqI2ttkWdesWVMcS6/Z2NigTZs2wvNQokQJVK1aFXKELep85PvW5dHc1xVnkkuiw6myuPMsWnrh+W1g+yggKU7bQ9QJHryIwZ5rUlR3//oZV3/rW1fav/LUQ8Qlcmocwyjx9/fX2CaLmixbckmT25nc0mRtv8uiJmtcCQkczYcrS2RmBLnIlSKtLKOpPD4yMhJhYWEq0SSoche56HPC9evXUbduXY19tE37iS5duiAuLg4+Pj4YOHCgeCBRztPTwwuJM73Wq1cvYd2TF0COsEWdj5gYG2F6t6r4ZMFJnH8YgT6Lg7BpcC0UXtcHCLsCKFKBNlO1PUzZQ5He5AlsUKYwyrjaZnhM0wqu8HC0El6MzRceo3tNzwIfJ6NfWJmZCMtWW9fOK0hU1SGR3rt3r7A6S5UqJUpd0txsYmLWFf7IIlWH5qRTU1NzdHxeuvSzQ/HixYVbm+bg6TOT5f3777/j8OHDwoo+d+6cmF/fs2cPxowZI+azKeJdbilgbFHnM1bmJljQ2x8lnK2FiAz45xziG40DXCsCDb7V9vBkD5UHXXvmkVgfWN8ny4eiPnW81ISdo+yZ3EHCQu5nbSz5GT1N88HkLiaXM83Xkms4ODgYBQkFvlHwFomier11Es6cUL58efF51KHtChUqqLbpQYTm4MlVT6J84sQJXL58Wbxmamoq3OK//fabmHun+3DgwAHIDbaoCwDnQhZY0rcmPvr7GC4+isTnJ4tg7qD/NIu039gOlG4OmPA/iTorgx6KucJybraoWyrrZgldaxTHtL23cPtZNI7eeY76pQsX2DgZRlegKOeNGzcK8aIHgh9//DFLyzi/GDZsGCZNmiSs+nLlyok561evXuXoIeXrr78WAW40t0yCu3XrVvHZlFHsFH1ODwABAQHCFb98+XIh3OTy3rZtG+7duycCyBwdHcX8ON0HihyXG2xRFxDeLjZYEOgvopb3XX+G8duup1l9l9cDqz8BlrYFXqelLxg6icmpWHo8WGVNv+s/sJ2lGbr4FxfrysIoDMNoMnXqVCFMVKSExLp58+aoVq1agY+D0rEoOK13796oXbu2mCunsVCqVHbp0KED/vzzT+HG9/X1FdHdFEX+4YcfitfJhT1//nwxb01z7CTgJOaUDkavkag3atRIWOYU+LZq1SpxHrlhpDAwH+GjR4/EvEVISAg8PKSiGQXJzstPMXTlOTHn+n2r8hj4gQ9wfRuwaTCQGAXYFAY6LwK85ZkmUJBsOPsII9ddRBFbCxz9tpF4yHkXwc9j0PCPQ+L+7h/ZACULFyqQsTK6TXx8PO7fvw9vb+8cCQWTd5A1S4JJFjJFouv79+pRDrRI6xb1rFmzRHI9fQhyT1C4f1ZQQv1nn30mIggpgb1MmTI5DunXJi0rFRUCTUzccV3k/qJ8G+DTw9K8dUw4sKw98N8U+ubCsAucSClZgXW8siXShJeLDRqXcxXrS44V7LwbwzDZ58GDB8LavXXrlpgzHjJkiBC1Tz75RNtDkx1aFeo1a9aIvLexY8eKIALK7SPXR2Yh/xSVSCH1NOG/fv16Ec1H/9DFihWDLkF1qpWBT1+tvYAzwS8B55JA/71AlR5SNPiBn4BV3YDYzAsK6DPH777AjdAoEf3aIyBnEdz96nmpelVHxuauDyzDMPmDsbGxmEOmymjkmiaxJtc0WdWMjISa5koot40qyVCUHs0R0IT/okWLMjye9lMlHKouQ/+wZIk3aNBAI3lfFxABHG0qiJQimocdsOwM7oVHA+bWQIe/gXYzAVNL4PYeYG4D4PFZGBpKa7qLvwccrM1z9N7aPs4i+EzqVZ11bijDMNqB3L4UoU051VSV7Pjx47KtDGawQk3W8dmzZ0WknmowxsZim8LnM4Iq51DQAbm+KbS/YsWKokIORfVlRkJCgvgSKJeoqCjIAUonmvFxVfgVd0BEbBL6LD6N59EJ0ovVeknWtaM3EPkQWNQCCJpvMI09bodF4dDNcFDsWL83hUxy+iBEleEICkbjXtUMw+gyWhPq58+fC4ElwVWHtkNDQzN8D4XSk8ub3kfz0pRW8Mcff+Dnn3/O9DoU/k85e8pFPb9ODjnWCwP9UdzJCg9fxmLA0jNpVbWKVgYGHQLKtQFSEoEdo4ANA4CEN9XN9JiFbyK2m1VwFXPO70M7P3c420i9qpVVzRiGYXQRrQeT5TQqsEiRIpg3b54oNdetWzd8//33wmWeGVRLllwryuXatWuQEy5vcqwdrM1Em8bhq88jJfWN5WzlAHRbDjT7GTAyAa6slwLN9NiyDo9KwMbzj8X6gCwKnLwL0av6TfMOTtViGEaX0ZpQu7i4iIIfVO9VHdqmSjkZQZHeFOWtXiiEAg/IAs+s/B1FhlNNWuVCZePkBqUQze8t5ViT9ffTNrWHCfL/1hkG9NkO2BaV1vW45+s/Jx+IeXuaEvAv4Zirc/Ws5QkzEyOcedN5i2EYRhfRmlBT71CyiqnVmrrFTNs0D50RFEB2584djSo6FNpPAk7n02VqeDlhalcpKG7J8WCV+1cFdd4adhbwVevV+uwGkPxmXlsPiE9KwfKTD8T6wPreuS6jyL2qGYbRB7Tq+qbULEqvWrp0qeh2Qnl0MTExIgqcoIo15LpWQq9T1Df1HyWB3r59uwgmo+AyfaBNZXf8r5XUovHn7ddEcRQNzNXma6mC2dI2wOKWQMxz6AMbzz3Gy5hEFHOwQgvfjL0qOUUZjLbt0lOEveZe1QzD6B5aFWqaY6bSb9S1pEqVKrhw4YJo3q0MMKO2a0+fPtUI59+9e7co5E7l4KjpN4k2NUbXF6hUZq9aJcQ09JdrLuDsg1cZHxjxAEhNBpLiAeO867SjLVJTFVhwVErJ6lvXC6YmefPVpF7VNb2ckJyqwD8nJGudYRhNqOTml19+qdqm1Nfp06dn+R7yeFGqbG7Jq/NkBXXFIo3RVbTeAYKaiWfWrJw6naSH3OLUGFxfoS/t2LYV8DQyTtQEH7D0NDYOrStqhWvgWUtK4bKwBaxyN5crBw7efIZ74TGwtTBFtxpSve68ggqgBAW/xIpTD/B5o1Ii0Ixh9AGq1Z2UlCQMnPQcOXJE5CVfvHhRo5d0diBjKH17zLwQSxJkMsjUIWOMao8zehL1bSiQNTmje1VU9rDHq9gk9F0cJFzCb+FSGrBVcxGfXQo8vQhdZMERaQ65e4AnbC01+9jmlqYV3ESvarqXm99ElDOMPtC/f3/RZ5nqRqeHmlP4+/vnWKSJwoULi+JTBQEFD1PQL5M5LNQyhXrSLgysIQQm+AXlWJ8WwVaZcmMHsPULYEkb4MFx6BJXHkfixL0XoggM1fXOazR6VR/jXtWM/tCmTRshqlSKU53o6GisW7dOCPmLFy9ElyoqtUziSz2oqUtUVqR3fd++fVtY59STgWpR0MNBRt2wKCuHruHj4yPqXJC1T9D4xo8fL6x78hrSohxzetc3lRKljlbUjpK6XA0aNEh8HiXUS5u6ZtG0KQUS0zEUp6S8VnaggOQJEyaIZhj0kEBucXWvBGURkaeXzk+fmdpiUk0Ogn4/yDvg6ekp3uvu7i6mYfMTFmoZU9iWcqxrwN7KDOceRuDL1RfScqzT41UXKFEXSHgN/NMRuLUHusKCN+VCW1cqKgLJ8gPqVW1jboJbYdE4dudFvlyD0VMSY3K+pCSnvZ/WaV9SXPbOmwNMTU1F0C2JnvoDKIk0FYYigaYOTpRhQ8G3V65cEcLXq1evdzZAUhe1jz76SGTWnDp1StStIFFOD6W+0jioVgW1nqRA4WnTpqnikUaOHClaSJKrmxbalx4KJqZ+D+QKJ/c7fY59+/a9NT168OBB3L17V/ylYGS6bvqHlayg8VGxLBL7S5cuiWu2a9dOPJAQM2bMEJUw165dK3pKrFixQjy8EBs2bBCfi1pq0vH0kEEPP3o9R81kTakitpjXqzp6LQzCrquh+GXHdVEn/C0s7YGeG4C1gcDt3cDq7kDHuUClzpAzNBdPEdnKQLr8QtmrmlLfyKquV9ol367F6Bm/SCl+OaLLEsC3o7R+Yyuwrg9Qoh7Qd3vaMdMrAbEZPDSOi8zRpfr164fff/8dhw8fVvVhJrd3p06dVBUZR40apTp+2LBhIiiXRKhmzZrvPD8J5Y0bN8R7yHokKNumZcuWGsf98MMPqnUSNbrm6tWr8c033wjrmPpN04NFZnUyiJUrV4oHi2XLlqnmyGfOnCnm4n/99VdVoDEJOe2nmhrlypVD69atRWov9Y7IDiTQ9LDx8ccfi206N4k+eRGooyMFMpcuXRr16tUTFj9Z1EroNfoMVO7azMxMWNbZuY+5gS1qHSDAxxlT3uRYU351pjnBZlbAxyuASl2kiHAqOXp6AeQMCSdFZAd4O6GSh32+Xovc6pSafeAGBa7pfylWxjAgoapTp46qmRHVmqBAMnJ7E2RZU39nsvqcnJyEYJLokuBkB0qdpYwbpUgTGdW6oG6IVOuCRIyuQcKd3WuoX4uaLKkHstWtW1dY9WTZKiHLXL3wFbmoM+u6mB7q+fDkyRNxXnVom66vdK9T0FvZsmWFW3vPnjQPZZcuXRAXFyfc+/RgsGnTJiQnq3lQ8gG2qHUEql39+FUcft11AxO2XYO7gxWaZ5RrbGIGdJwHWDoAp+cD20cCca+A+qNkV9EsOiEZK089zHW50OxCkfONyxUR0fT0gDChfcV8vyajB/zvSc7fY6IWHFWurXQOo3R20ZeXkVeQKJOlTNYgWdMlS5YUnQUJsrbJ1UvWIok1iSClYmVWzfF9oEZKPXr0EPPQ5EYmK56saXIv5wdmZpoBp2T1qhfCyi3VqlUTvbF37twpPApdu3YVFjT1mqCHFnpooP00Vz906FCVRyP9uPIKtqh1iMENfERvZpqKoprg5x9mkmNtbAy0+h344Btp+8DPwJ4fZFcjfN2ZEETFJ8PnjYAWBMoCKOvOcK9qJptQoaGcLiZqNhCt0z7yeGXnvO8BCQl1HyTXMbmNyR2urOxHrSTbt2+Pnj17CmuVLEEqGJVdqExzSEiIRk2L9Cmy1KKS3MPUe4Eizclt/OCBZt0CmuPOqtOh8loUcEZz1UqOHTsmPhtZt3kBlZIm7wCdVx3aVm/aRMfRPDrNtZO3gOamqeAWQa58csfTXDalEdODCgXB5Rcs1DoE/ccb384XjcoVQXxSqui29eBFJsEn9J+00fdA81+k7RMzgX8/1wxy0SIUFEdzxQS1pDQ2Lhhrv3bJtF7Va85wr2pGPyBXM4kKVXIkQSXXrRISTbL8SEzJtfvpp5++1WMhK8iSpGjuwMBAIaLkVidBVoeuQW5usqIpyIsEjFzC6tC8NVmp5FKm7onUgjg9ZJVTlDVdiwLfaN542LBhIvgtfafF3PD111+LeWkSYLKOqWgWjYsKaBFTp04VkfE0N08PNRTURi59BwcHEbS2cOFCMT7q6Lh8+XIh3Orz2HkNC7UO5lj/1b0qKhazw4uYRNHHOsMcayW1PwPaz5LcbheWA+v7yKI++O6roQh5GQdHazN0quZRYNcVvarfWNVLjz/gXtWM3kDu71evXgnXs/p8Ms0VkyuX9lOwGQkOpTdlF7JmSXRpXpaCpgYMGICJEydqHEMR01999ZWIzqZUJ3oooPQsdSi4rUWLFmjYsKFIKcsoRYxSu2j+nCzXGjVqoHPnzmjcuLEIHMtLaN6ZSlhTJDpNB1BqFkV50wOHMoL9t99+E94BGkdwcLBorUz3gsSarGya06YcdXKBb926VaSJ5RdGCgNLKqXCADTHQK4cyqHTVZ5FxaPjrON4HBGHKsUdsHJggMi9zpTrW4H1/aTe1tQ6s3xbaJOP/j4mUs6GNSqFkc3yxqWVXSgfvc7kA+IBZ3aPamhZqWiBXp+RHxRpTNaet7e3sOgYJr+/VznRIraodRTqDLW0X1of689WnENSVtYhCXOPdUCTcVoXaapfTiJtbmKMXrXzz12UZa/qAE+xrnS/MwzDyBUWah2mVJFConqZpZkxDt4Mx+iNl7OuuuXzIVDvq7Tt2JdSFy4tFTjpUNVdPHBog561Sohe1aeDX+HSI+5VzTCMfGGh1nGql3DErE+qiTKZ688+wpQ9abmGWZIQDazoAixqDryUhLMgePgiVsxPE/3r5X9KVma42lmKtqLE4mPBWhsHwzDMu2Ch1gMal3fFLx2lnOBZB+9i6fFsCE98hFQVKT5SapVZQJCrmaqgflCmMMq62UKbpPWqfsK9qhmGkS0s1HpCtxqeGNm0jFgft/Uqdlx+h0vb3gPotxvovRlwzaAkaT5Aectrz4SI9YH1JZHUJlQJrYaXI5JSFFh+kntVMwwjT1io9QjqtdyrVglR14QaeJy4+47mE7augHvVtO37R4A7+/NtfCuDHiI2MUXkMdcrJY9a20qresWph1l3J2MMgrysbsUwqXn0feISonoE5QiPa+eL8KgE0cBj0LIzWDu4NsoXtXv3m5/dAFZ1B5LjgU4LAN/s51lmh8TkVCw5LkVY96/nraqapG2aVnAVHbsoze3fC4+FZ4IxPKhqFuXIUg1oyvGlbbl8Rxndg4J6qURreHi4+F7R9yk3sFDrGRRUNv3jKui9KAhB91+iz+IgbBhSBx6O72gC7+QDlG4CXN0ErO8rzV1XD8yzcW2/TPPACaJ1Z7sq79GNKB8LyFCv6ok7rmPR0WB09S/OP9AGCP2YUq4rVfUisWaYvIAKuFB3Lfp+5QYWaj2E8oTn9/ZH1zkncDMsCoGLgrB+cB042mTxVGdqDnRaKLXLPLsE2PqFFHBWVyqpl9uny/n/SdZ0YO0SsDBN63ojB6hX9bR9t8S9On73BerKxC3PFCxk9dCPKnVCeldNaoZ5F9Tdi9p65sWDPwu1nmJvZYYl/Wqg09/HcTc8Bv2XnsaKAbVgZZ6FSBqbAG2mA1aOwNFpwN4xUuetxmNz1XnrxL0XuPb0tcj37hFQ8AVOsnOvulT3wNITD7Do6H0WagOGflSpA1J+dUFimPeBg8n0mKL2VqJ6GQkRVQL7fOW5d9e2JkGm6mVNxkvbJNjbvgJS39/CWHBEsqa7VC+etVWvRfq8CSrbf+MZ7j/PpNEJwzCMFmCh1nNKu9piYaA/LEyNhQh9v+lK1tXLlNT7Emj7Jyk3cHYxsKE/kJzz/rV3nkXhwI1nQv+pS5ZcUfaqJpZwWVGGYWQEC7UB4O/lJDpuUSfJNWdCMG1vNnvRVu8DdFkMGJtJQWaruwOJsTm69sKjkug1Ke8qxFDOKB8k1p19hMg47lXNMIw8YKE2EJr5uuHnDpXE+owDd/BPdgt8+HYEPlkNmFkDd/YB/3SQ5q2zwYvoBGw491isD6yvvXKh2aVOSWeUdbUVud7r3hRmYRiG0TYs1AbEJwGe+LKJ1G91zL9XsOtKNhtylGoC9NosRYSHnAJOzc3W2+hhgPKn/d5UANOFQKK+db1U9b+5VzXDMHKAhdrAGN64NLrX9BTVy75YfUHkWmcLzwCgzw7JHV5/1DsPpypf/5yQrPb+9X1yn6JAFX4SooCYF1LHr1cPgKgw5DUdqhaDo7WZKICy73ren59hGCancHqWgUGC+VN7XzyPTsDea2EYsPQ01g2uk70GGW4V3wSYvSE5ATi9AChRJ60UaeQjYXE/ePISXyaEwsEGaH3HGbiVBKQkAinp/75Z77kBsCsqnePgL8DJOUDAp0Cj76V9EQ+AGVXeHlOtoUCziVSxIg97VZfAzIN3RAGUFhXfjIlhGEZLsFAbIFSNi4LLei44hTMPXomCKBuH1oG7g1X2T0Im+fYRwPnlUp61UqhjwoHjM1AWQFn6dlFW1+VsnC9JLUiNxDshEkiMTttnopbWZWQibSfHASf/lqqotZ0BmOTN17lX7RKYc/gugoJf4vKjSNG8g2EYRluwUBsoZDkuCPRHlzkncPtZtCg5un5wbThYZzPPOTEGMLMBKnQAXKR5b0EhNzws1x9brjyHkYk5BnxYFhYWlpKwmpi9+ZvBuq2a5VrrM6BKT6nwihJ6/fsw6VgqzEJcXA1sHgpcWCGJ+kcLpApredKruig2X3iCxcfuY2q3DCx5hmGYAsJIka2kWv3h0aNHKF68OEJCQuDh4QFD50lEHD76+zhCX8fDv4Qjlg8IECKeG3osOIljd15gQD1v/NAmn1toXt8KrO8nWeEU9Nb1H8D8HXXNs8GlRxFoN/MYzEyMcOzbRihiZ5knw2UYhsmpFnEwmYFD7u5l/WvCztJUuMGHrTqfq2jnq08ihUhTc5C+BVHgpHxb4JM1aeljyztJrvBcUtnDQTy4cK9qhmG0DQs1gzKutlgQWAPmpsYiwOzHf69mr3pZBix8Uy60VaWion1kgVCyEdBrE2BhBzw8DixtJ0WH51EBlOXcq5phGC3CQs0Iano7YcbHUvWyVUEP8ef+2zk+R2hkPLZclFoEktu7QPGsBfTZBlg7A+E3gBd3cn3KZm96Vb+MScSWC9z6kGEY7cBCzahoUdENE9pXFOvT993GylMPc/T+pSeCkZyqQE0vJ/gVd0CBU9QP6LsL+HillPedB9HxgXWkbl+Ljt1/by8DwzBMbmChZjToWasEvmhUSqz/sPky9lwNzdb7YhKSseLNXO6A+lpsvlG4DFCqcdp22FUg/OZ7n66bvyeszU1wIzQKJ+7m3p2eF9wNjxbpY9muLMcwjE7DQs28xVdNy6Cbf3GkKiCCy84Ev7t6GdXGfh2fDC9na9GAQxa8uAss6wAsbgmEXXuvU9hbm6FzdQ+VVa0t7oVHY+aB22gx/T80/uMwJu+8gcHLz6manjAMo79wHjWTYfWyiR0riupl1Bqz/9IzIseaWmZmREqqAouOBYv1/vW8YUwT3XLA0gGwc5d6aSurnr0Hfep4YdmJB6pe1QXVBSz4eQy2X36K7Zee4trT16r9psZGKF/UDpcfR+KnbddEPfUhH5YskDExDFPwsFAzmc7PzvykGj5ZcBLnH0aI6mUbhtZBUfu3I7n3XgvFw5excBDWZ3HIBhtnIHCrVOpUvXhKDvEpXAiNyhURfbWXHg/GuHa+yC8evEgT56tPNMW5bikXtK5cVAS52VuZiTgCCvr7ddcNJKWk4ovGaoVnGIbRG1iomUyxMjfBosAa6DTnOO6Fx6DPotNY+2lt4Q5WZ/6blKyeASXEe2SFpZ3mNnX+oipnFdrl6DTUVYuEmlz8I5qVgZ2l5j3IDQ9fxErifPkJrjxOE2fKRafWm1QlrVkFNzjamL81RUEpdb/vvompe28JsR7RtEzuG6AwDCMrWKiZLCFxWNavJjrNPo6bYVEYuOyMKJCirF527uErnH3wCuYmxuhdW4qQli33DgE7vwGMjIH2fwNVumf7rfVKuaB0kUKi3Ora0yEYkMv+2iEvJXHecfkpLj2KfEucW1cqKnqIO6UT5/R81rCUuPcTd1zHXwfuCDf4dy3LsVgzjB7BQs28Ew9HayztV1PUBadGFV+uvoBZPaoJUVEWOGlXxV3+ZTa96ks1xC8sBzYPluqD1xyYrbeS8FEBlNEbL2PJ8WD0restPn9OePQqVggzubUvqokznaa2EGd3NPd1hXMhixydd+AHPqLU6bit1zD3v3tITEnFmDYVWKwZRk9goWayRTk3O8zv7Y/eC4Ow62ooxvx7BYMblMTONylCWk3Jyi7UzKPdX4BFIeDUHGDHKCDhNVB/ZLbe3rFqMfy26wYevYoTFdwo7/xdUF/rHZfIrf0UF0Ii0oZiBNTycRZzzs193eCSQ3FOT5+63jAzNcb3m65g8bFg4Qaf0K6ifAL7GIbR7fSsWbNmwcvLC5aWlggICEBQUFC23rd69WphNXTo0CHfx8hIwjL94yogQ23FqYfotfCUSOGqX9pFCLlOQH2rW0wGPvhG2t4/Adg3Tmrb+Q7I3f9JgOc7U7Wo0cmCI/fQ8e9jqDv5gHBLk0gLy9nHGT93qIhT/2uClQNrid7XuRVpJXSu3zpXFv8+y08+FNY/ReQzDKPbaN2iXrNmDUaMGIE5c+YIkZ4+fTqaN2+OmzdvokiRIpm+Lzg4GKNGjUL9+vULdLyGDtXwHtfWF2O3XEXwC6mHdG7nawscUrJG30uW9d4xwNFpQEIU0PJ3ScizoFctL8w9fA9B91/iyuNIVCwm9ap+GhmHHZdDsf3SE5x7GKFxKarURgFhzSu6oYht/k4PdPUvLtzgI9dexJozIcKy/r2LX47d9AzDyAetC/XUqVMxcOBA9O3bV2yTYG/fvh2LFi3Cd999l+F7UlJS0KNHD4wfPx5HjhxBRETaDyOT/wTW8cKzqHjMOngX5dxs8UFpF+gkdYcDFrbAthHA6QVAQjTQfhZgkvl/Czd7S+Gu/vfCE8w8cAcBPk5izpk6j6mLc4034tzC163A5+47VvWAqbExvlxzARvPP0ZSqgJTu/rBzEQWDjSGYXRJqBMTE3H27FmMHj1atc/Y2BhNmjTBiRMnMn3fhAkThLXdv39/IdRZkZCQIBYlUVFReTR6w2ZUs7Ko6e2MMq6FdDtoyb+f1HVr4yDg0mopwKzzIsA0c3c0BZKRUNNcPS0E3QJqi0nR2i0rFYWrlgPr2vq5C2Eetuoctl58gqTkVMzoXlWkczEMo1u81/9aanRNTa+V0Jzyl19+iXnz5uXoPM+fPxfWsaurZslJ2g4NzbjG9NGjR7Fw4ULMnz8/W9eYNGkS7O3tVUuFChVyNEYmY0icG5QpnGEBFJ2jUmeg23LAxAK4sQ1Y2Q1IjMn08CrFHdCwbGGxTuI8tm0FnPiuMdYNriOCurQt0koo2G1Oz+oifYseKIauOIuEZG7XyTAGIdSffPIJDh48KNZJUJs2bSrE+vvvvxfWbn5B1nCvXr2ESLu4ZM/dStZ6ZGSkarl27f1qPjN6TrlWQI+1gJkNcO8gcHtvlofP6+2PS+OaYf2QOsLCJpe4HGlc3hXzA/1hYWqMfdefYdCys9xbm2EMQaivXLmCmjVrivW1a9eiYsWKOH78OFasWIElS5Zk+zwktiYmJggLC9PYT9tubm+nvty9e1cEkbVt2xampqZiWbZsGbZs2SLW6fX0WFhYwM7OTrXY2mZcr5ph4PMh0Hsz0HwS4Jt1JgG5lfOyOll+Qp6PxX1qwMrMBIdvhaP/0tOITUzW9rAYhslPoU5KShICSOzbtw/t2knlGMuVK4enT7Pfes/c3BzVq1fH/v37VftSU1PFdu3atd86ns5/+fJlXLhwQbXQtRs2bCjWixeXUZ1pRjcpXhOoPTRtO/Yl8PoJdJ06pVxE0RobcxMcu/MCfRafRnQCizXD6K1Q+/r6iuhsCuTau3cvWrRoIfY/efIEzs7OOToXpWaRK3vp0qW4fv06hgwZgpiYGFUUeO/evVXBZpRnTda7+uLg4CCsZFon4WeYPINStpZ3AhY1B17eg65T09sJy/oHwNbCVKSXUaOV1/FJ2h4WwzD5IdS//vor5s6diw8//BDdu3eHn5+f2E8uaKVLPLt069YNU6ZMwZgxY1ClShVhGe/atUsVYPbw4cMcWekMk2fEvwbiI6S0LerApQdUL+GI5QMCYGdpKmq091pwCpGxLNYMI2eMFIpslGTKAIrWfv36NRwd09oH0vyxtbV1loVKtA1Fq5OLnCLXPTw8tD0cRu5EhQHRYUDRytAnqFgLVZZ7FZsEX3c7/NM/4J0NQBiG0Y4WvZdFHRcXJ3KTlSL94MEDUVHsXdXEGEbnsHXVFOl7h4HgY9B1qKLaqkG14FLIXPS9/mT+STyP1g+vAcPoG+8l1O3btxfR1gRVBaPSn3/88YeouT179uy8HiPDyIPQy8Cq7sDyj4Db+6DrUH321YNqoYitBW6ERuHjeSfx7HW8tofFMExeCPW5c+dUNbbXr18v5pPJqibxnjFjxvuckmHkj3MpwKsekBwPrPoYuLoJuk6pIrZY82ltFLW3xJ1n0eg276SoW84wjI4LdWxsrCofec+ePfjoo49E6c9atWoJwWYYvcTMSqpg5vsRkJoErOsDzKkHHJuh0ylc3i42WDOoNoo5WOH+8xh0m3tS9M5mGEaHhbpUqVLYvHmzmATfvXs3mjVrJvY/e/ZMFBVhGL3F1BzotAAIGAIYm0nu8L0/AlMrAEvbAeeXA/GR0DU8na2x5tNa8HSyxsOXsUKsH77pjsYwjA4KNaVSUYtJ6iFN6VjK4iRkXVetWjWvx8gw8sLYBGg5GRh1C2g9FfCk778CuH8Y+PczYEoZYG0gcGMHkJwIXcHD0RprP60NHxcbPI6IQ9e5J3AvPFrbw2IYg+e907OoxjflN1MONbm9Car3TRY1VRCTK5yexeQLrx4Al9cBl9YCz2+m7f/qKmCvW98zCijrseAUbj+LRmFbC6waGCDmshmG0Y4WvbdQq1+M0BXRY6Fm8hX67xR6SRLsqKdSy0wlW4cD1i5AzYGA7du17OUEpWr1XHBKRIM725hjxcAAESWuDV7GJOJ2WJR4cKCAt9vPohAVn4xfOlYSaWYMo4vku1BTPe6ff/5ZpGRFR0uuMQouGzlypOigpbSw5QgLNaMVosOBP8oCihTg87OASylpf2qK5EqXIa9iEtFz4SmRZ+1obSaKouSXMNLPUHh0Au6EkRBLYnw7TBLmFzEZTx+Qtb9xSB0Ud7LOlzExjFy0yPR9LkBiTD2hJ0+ejLp166r6RI8bNw7x8fGYOHHi+42cYfQVC1ug03zgkZpIE+v7ScFnlbsB5dtIx8kERxtzrBxQC70XB+FiSIQoikJi7VfcIVeCHPo6XoiwZCFHqdYj4zIvZerhaIXSRQqhtKstShUuhEXH7gtrv++S09gwuA7srXWjkxnDvA/vZVG7u7uLphzKrllK/v33XwwdOhSPHz+GXGGLmpENVEP8Nx8g5U1FMFMrqS82iXbJRoCJPMQnKj5JdNui2uDU0GNJvxqoXsIpy/ekpipEQJrSVZ0mzNGZdu0yMgJKOFmL+fDSroUkYS5ii5JFbGBtrmlTUK53x1nHhegHiGYjNWFhKk/PBMNoxfVNXawuXbqEMmXKaOynEqLUWINKjMoVFmpGVlBXrsvrgUtrgBd30vZbOwMVOwGVugIe/pKKaZGYhGRhvVLXLWtzE9HfOsDHGSmpCpFzrRRiEmUSY1piE1MyPJeJsRG8nK2FCJMgl3ojyD6FbWBpln2xvf70NbrMOSGEv52fO6Z3qwJjY+3eJ4aRjVBTyVBa0lchGzZsmIj8PnXqFOQKCzUjS+i/4ZPzUhDalfVATHjaa47ekpVduSvgXFJrQ4xNTMbAZWdEP2tLM2P4uBTC3fBoJCSnZni8mYmRKKZCIizEWFjJtvBysc4z6/fI7XD0XXwayakKDP2wJL5pId+ME4YpUKE+fPgwWrduDU9PT1UO9YkTJ8QFd+zYoSovKkdYqBnZk5IM3DsEXF4LXN8KJKkVHileC+i7Q2sBaPFJKfj0n7M4fCvtQcLc1BglCytd1ZIgk/u6hLM1zEzyP7B03ZkQfL3+klif2LEiegSUyPdrMozsg8kaNGiAW7duYdasWbhx44bYR2VEBw0aJKLB5SzUDCN7TEyB0k2kheaxb+6QLO27BwArhzSRpiC0+Y0lt/iQ42lz2vvGS8fSfiPjTBZyEau97lkLaPBN2hjW9JKKuLSdAVi/mY++uBqWdw9gkb0RQkonILWQG+yKloajRxmYOHsDtu6AFjI+uvgXF/Ph0/fdxo+br8Dd3goNy3EXP0Z/eC+hVgaUpY/uvnjxoogGnzdvXl6MjWEYi0KSy5uW6GdA/Ou01yi168VtaZ3EVsmrYODphZxdxzxditONbYAiFWj1R9q+x2fFXDo9Jngp911Xe4+JOeBQAnD0Apy8pb9ulQDvD5DfDG9cGo9exWH92Uf4bOU5Ubu8kgfnWDMGLtQMwxQwhYpIixJK5eqzQxJUdaGu9xVQ5RNpP81sib8ZLTTr9eZ1u2Ka12r9h7RfPV2sXBvAwVPan5IEvH4sPRTQEvEQSEmUHhyUDw9E6WaaQv1PR8CmMND8F8DGRdqXFAeYWuYqYM7IyAiTPqqEsNfxOHL7OfotPc051ozewELNMLoKubq9pDoGGhStnPtz+/d7e59PA2nJbF5dJdz30wTcvVraMXGvJJc80WZa2v5d3wEX10gWuPqitMrp4YA6l70Dmg//u0c1EQnOOdaMPsFCzTBM3syrO5LbmwK5MhFzEwugyxIgKhQwt9Gsk54cB4Rfl5aMsC0qRb8rRdytIlCu9duHWZphcd8aIseaUsQG/nMG/3CONWNIQk0BY1kRERGR2/EwDKOv0Dy4b8e39/dYB0SGSBb4SzVrnCzzl8FAYpRUN52Wh8el91C6mlKoyYVPrnhqQUoOBXsrIdZd55wQed+j1l3Cn5xjzRiKUNvb27/z9d69e+d2TAzDGJoL38lHWtKniZMIk8tcCLhSxO8DVXqmHRN2BVjaVhLvFpPFXHf5onaY3bM6+iwOwtaLT0QJ0m85x5oxBKFevHhx/o2EYRgmPRRgRulhtHhUz/gYyjUnMac5crWAtHrOUZjcqTJGrbuI2YfuopiDFXrW4hxrRvfgOWqGYXSbBt8CnrUBSzWP34u7wF/V0NmtMoqUa4RRN0pjzL9XUNTeEo3Lu2pztAyTY1ioGYbRbagATMmGmvsenwOMTUVv8A9wCSctjXA8pQK2r/oArn0+Q0Wf4toaLcPkGBZqhmH0j8pdgFKNgaubRFU345CTqGdyFfVwFfHLFiK2dAtYV+8OlGqiCkJjGLnCQs0wjH5C89o1+kvLq2AknF+DsKPL4Jn6CLi9RVqsHKVIdApEKx6g9S5lDJMRBV+Yl2EYpqBx9IJFo29h/sUZBJr9jvnJrfDK2FEKQjuzCFjUHNg/XtujZJgMYaFmGMZgcHOwwuj+H2OGSR9Uj/0LMz2mQOHXHTAvBJRpkXbg04vA8ZlScRaG0TIs1AzDGBTl3Owwp1d1GBubYModd/xq+SUw6rbk+lZydgmw53upExnDaBkWaoZhDI66pVzwayepJvqcw3fxz7lwzflpj5rSQl3LlDy9BKzrC9zcJVVCY5gCgoPJGIYxSDpV9xB9rKfuvYWx/1Ifa7Uc6yrdpUWdS2uAqxulheqN99kO2HtoZeyMYcEWNcMwBsuwRqXQ1d8DqQrg85XncelRFv0K/D4Gag0FrF2kUqYrPwYSogpyuIyBwkLNMIzBQn2sJ3ashPqlXRCXlIJ+S04j5GVsxge7VQJaTAIGHZR6aoddBtb3l1p8Mkw+wkLNMIxBo+xjTY08nkcnikYeEbGJmb+B+mN3Xw2YWgK3d0tBZwyTj7BQMwxj8Ig+1n1qiFrgd8NjMGjZWcQnpWT+Bg9/oONcaf3UHODUvAIbK2N4sFAzDMOQZ9veUvSxtrUwRVAw9bG+iFSavM4M3w5A47HS+q5vgVt7CmysjGHBQs0wDKOWYz23V3WYmRhh26Wn+HX3jazfUO8roGpPQJEKrO8LhF4uqKEyBgQLNcMwjBp11HKs5x6+h39OBGd+MOVet54GeNUHEqOBld24mhmT57BQMwzDpOOjah4Y2bSMWB+75Sr2XQvL/GDqvtXtH8C5NPD6MXD8r4IbKGMQsFAzDMNkwOeNSqGbf3GRYz1s1XlcDMkix5q6cPVYC9QdDjThsqNM3sJCzTAMk0mO9c8dK+KDMoVFjnX/pVnkWBNOPkDTCYAJF3xk8hYWaoZhmHfkWFd4k2Md+K4cayVUC3zrcODM4oIYJqPnyEKoZ82aBS8vL1haWiIgIABBQUGZHjt//nzUr18fjo6OYmnSpEmWxzMMw+SGQhamIm2LaoHfC4/BwGVnss6xJq5skDpw7fwGiHxcUENl9BStC/WaNWswYsQIjB07FufOnYOfnx+aN2+OZ8+eZXj8oUOH0L17dxw8eBAnTpxA8eLF0axZMzx+zP8ZGIbJH1ztKMe6JmwtTXE6+BW+WnMBcYlZiHXlboB/P6DLUsC+WEEOldFDjBQKRRYZ/fkPWdA1atTAzJkzxXZqaqoQ32HDhuG777575/tTUlKEZU3v79279zuPf/TokTh/SEgIPDy48w3DMNnn+J3nwv2dlKJACWdrkcZVy8dZ28NidJCcaJFWLerExEScPXtWuK9VAzI2FttkLWeH2NhYJCUlwcnJKcPXExIS8Pr1a9USFcXdbhiGef8c68V9aopSow9exOLjeScx5t8riEl4R2MO6ra1aQiQFFdQQ2X0CK0K9fPnz4VF7Or6pgfsG2g7NDR7RQO+/fZbuLu7a4i9OpMmTYK9vb1qqVChQp6MnWEYw6ReaRfs/uoDdK9ZXGwvO/EAzaf/h2N3nmf8htQUYEUX4OJKYPMQchsW7IAZnUfrc9S5YfLkyVi9ejU2bdokAtEyYvTo0YiMjFQt165dK/BxMgyjX9hZmmHSR5WxvH8AijlY4dGrOPRYcAqjN17G6/gkzYONTYDWUwFjU+DqJuDgRG0Nm9FRtCrULi4uMDExQViYZtUf2nZzc8vyvVOmTBFCvWfPHlSuLJX7ywgLCwvY2dmpFltb2zwbP8Mwho3Suu5du4TYXhX0EM2n/YdDN9MFw3rXB9rOkNaPTAHOr9DCaBldRatCbW5ujurVq2P//v2qfRRMRtu1a9fO9H2//fYbfvrpJ+zatQv+/v4FNFqGYZiM07cmtK+I1YNqiQCzp5Hx6LP4tOi+FRmrZl1X7QHUHymtU471/SNaGzOjW2jd9U2pWZQbvXTpUly/fh1DhgxBTEwM+vbtK16nSG5yXyv59ddf8eOPP2LRokUi95rmsmmJjo7W4qdgGMbQoejvncPro19db9GrY/3ZR2g67bBmnfCGPwAVOgCpScCansDz29ocss7xOCIOVx5HwtDQeq27bt26ITw8HGPGjBGCW6VKFWEpKwPMHj58KCLBlcyePVtEi3fu3FnjPJSHPW7cuAIfP8MwjBJrc1OMaVsBrSq54Zv1l3DveQwGLDuD9lXcMa6tLxxtzIGOc6TmHY9OS0FmA/YDNpzilRkvohOw4/JTbLn4ROSwE2PbVkDfut4wFLSeR13QcB41wzAFAVUvm7bvFub/d0809nApZI6f2ldEy0pFgehnwILGQMRDwLM20PtfwNRC20OWDdEJydhzNRT/XniCo3eeI4VuoBrksZjTszqa+2Ydy6QvWsRCzTAMk49cCInA1+su4vYzaXqudaWiGN/eFy6x94GFTYGE11Ils45zJQUyUBKSU3DoZji2XHiCfdfDkJCclsZWqZi98Eq0qeyOGQduY+Wph7AwNcaqQbVQzdMRuggLdRawUDMMow0R+mv/Hcw+fFdYh0425hjXzhdtbW7AaEVnQJECNPweaPANDAm6FyfuvsCWi4+x80ooouLTCsf4uNigXRV3tPNzh0/hQqr9ySmpot76wZvh4j5uHFIHXi420DVYqLOAhZphGG1BgVAUDX4jVKqQ2KyCK6aUPAe7vV8DHjWAPjsAU3PoMyQ55GWgOedtl54iPCpB9ZqbnSXa+hVF+yrF4OtuJ1qNZgRVgqOqcJcfR8LL2Robh9YVoq1LsFBnAQs1wzDaJDE5FX8fuoOZB+4gOVUBeyszzK9yDzVa9oaRuTX0ldthUWLOmQT6oVpfbwdrM7SqVFRYzjW9nGBsnD33/7OoeHScdVxEglfzdMDKgbVgaWYCXYGFOgtYqBmGkQPXn77G1+sv4srj12K7YdnC+OWjSihqbwUkxgDmuufOTc+jV7HYelGK2KbPq8TKzATNfF2FONcvXRjmpu+XKXznWRQ++vs4Xscno4WvG2b1qAaTbAq9tmGhzgIWaoZh5ALNt8797x7+3HcbiSmpsLMwxqrS+1Eh4jCM+u8BrBx1Np2KrOczD6R0KsLMxAgNyhRGuyrF0KR8EZHKlhecuvcCvRYGiftHOeyUHqdvWqT1PGqGYRhDxdTEGJ81LCXmqr9efwnBISFwvL0BRkYv8fLsJjjV6wddTqeiKeYAbycx59yyohscrPN+HjnAxxm/d6mM4asvYNGx+yjmaIX+9fQrx5qFmmEYRsuUdrXFhiF1sPDoPQze8y3KKO5h5x53fGf6AD1qemZ73rag88QpnWrrxbfTqSp72Au3NqVTudln3DAp2ygUQEoSkBwPpCRKUwJmVhqH0IPAk4h4/LrrBn7efg3FHCzRomJR6Avs+mYYhpER98KjRVUzpdu4jrcjJneuAk9n7QWakUyQ1RzxKgLPgi/jyO3nWHjPXpVO1dT4DMrYJsLfwwaV3SzhTNpMopqc8OZvvNr6m7+VOgMVO0kXCL8FrO0FWDoA/XenXXhxa+DBUc3BmNkAbacDlbu+NcYf/72C5SelHGsKLqteQr5TB+z6ZhiG0VEoZ3jNp7Wx9HgwFuw+hRGPx+GP6a1RpUUgAmt75Yl1TXndr2KS8DImUVpiE/FKuR6TiJjoCNhE3oFj9F0EJXnjbJwbklIUaGZ8GvPMp6FQqgemJ/4m0qko13nErTGwjLgD3IW0ZAe3SmnrilQg/AZg5aR5TEbpWUkxwMaBwKtg4IOvVcdQKheVaX0aEY/9N55hwNLTIm3LWwdzrNPDQs0wDCMzKHK5Xz1vfBS1HA6nbqGi4j66bXPEjss18FtnPw3xofngyDg10Y1JxKtYtXV1Iab90YmISUwR77VCPEoZPUEZo0cobfwIfkaPUMb4ETyMnqvO/1tSV5xM6SDWH5h44TkcYWTnjjUf1UINZTpVSn3gdUkpB9zUEjCxkNYz/GsprRetkvaBHYoDvbcAZum8Bp0Xk4oDJnReC8DYDNg/Hjg+Q+rr/fI+0PZPVe45zfn/9UlVdJsr5Vj3WRwkCqI4F9Lt8qzs+mYYhpErqSlQrOoOo9u78Vxhj/YJE/Dc1FWU1FSKcURckpjGzQ5NjM+imvFtlH4jyMWNwmFMQpgB8ZaFEedQBjHlOsO4Snc4WpvDylwmecpnFgHbR0kV3bzqA93+0YiQpxxrStt69CoOVYo7YNXAWvIZ+xs4PSsLWKgZhtEpEqKARS2BsMt4ZFoCLaN/RBTenq+2szQV1bloKWaZiPaxG+GqCMexyhOl/dbmqHFsEOwfH9J8o7ULUKS8tBQul/bXOp0bWm7c2Qes7QMkRgHOpYEe6wCntGjvO8+i0Wn2ceFtaO7rir97VJdVjjULdRawUDMMo3NEPgbmNwKiQ/GyaH0EBfwFt5QwFI6/D4foO7CKuA1jmvNt8LV0PBVM+cVdWv/6LmDjIq2fXgiEXQGKVEgTZeVrukjoFWBlV6ltqE0RYNgZwNJe9XLQ/ZfoueCUyLHuW9cLY9v6Qi5wMBnDMIw+YV8M+GQ1sLgVnJ4eQYvNVaW5W3ViwtOEmlKY6n4J2LoBxmou3xr9oVe4VZT6ea/qBlTsrCHSRE1vJ/zR1Q/DVp3H4mPBKOZghQH1faBrsFAzDMPoAu5VgU4LgDU9pShp80JA4bJA4Tdu66J+msc3HQ+DwK4o0G+PZj/v+EjAwk5EhLf1c8eTiDhM2nkDE3dch7uDlagtrkuwUDMMw+gK5VoDX1yQUpLsPADj96uRrXeYqRVViX8tzel7VAdaTwVMzDDoAx8RWPbPyQf4cs0FuNpZoHoJmc/Bq8H/ygzDMLqEYwnAwZNFOjOCjwLh14Fbu6XpAGWOdTtfUWOcupcNWHpGFJbRFfhfmmEYhtEfyrUCPl4JdF8N2Llr5KbP6F4Vfh6U2paEPotP43l0Wi9sOcNCzTAMw+gXZVsCxaqlbd/cCTw+Kzp2LQisgeJOVqIndv+lZxD3pviLnGGhZhiGYfSXpxeBdX2luuHXt6GwrQWW9K0JB2szXAyJwBerz6u6fckVFmqGYRhGf3HyAbzqAslxUsT8iVko6WKD+b39YW5qjL3XwjBh61XR1EOusFAzDMMw+ouFLdB9DeBPvb0VwO7/ATu+Ro3idpjWVao3vvTEAyw8eh9yhYWaYRiG0W9MTKVUrWY/Uww4cHo+sLo7WpcthO9blReH/Lz9OrZfego5wkLNMAzD6D9GRkCdYUDXZYCpFXB7j8i3HuBnjsDaJcQhX629gNPBLyE3WKgZhmEYw6FCO6DPdsCmsGh0YrSgCcbUSEHTCq4ix3rgsjO4K7McaxZqhmEYxrDwqC7VCKfGJFFPYbK4JWb6P4dfcQdEiBzrIIRHySfHmoWaYRiGMcwKb/12A94NgKQYWKzrjhWVL8HTyRohL+MwYOlpxCYmQw6wUDMMwzCGiZUD0GM9UFVqdFIo7jGW9K0h5Vg/isQXqy7IIseahZphGIYxXEzNgXYzgS5LgSYT4FO4EBa8ybHedz0M47ZoP8eahZphGIYxbIyMAN8OqkYn/h422FtmC4oYvRIdt+YfuafV4bFQMwzDMIw6u/+HEvdWYpfzdBghFb/suIFtl55AW7BQMwzDMIw6tYYChcvDsePvCKzjI3aNWHMRQfe1k2PNQs0wDMMw6jiXBAYfhVHJhvixTQU0q+AKu5RXIsf6zrOCz7FmoWYYhmGYjMqOKvtYNy2Eg1ZfY3DSMvRddLLAc6ylkTAMwzAMkyGWD/+DpSIaQ0y3IsmoOFJS66EgYaFmGIZhmKwIGARY2iHu/Dr07fIjbG0sUZCwUDMMwzDMu/D7GFaVu0mpXAUMz1EzDMMwTHbQgkgTLNQMwzAMI2NYqBmGYRhGxrBQMwzDMIyMYaFmGIZhGBnDQs0wDMMwMsbg0rNSU1PF36dPn2p7KAzDMIyB8vSNBik1KSsMTqjDwsLE35o1a2p7KAzDMIyBExYWBk9PzyyPMVJouyN2AZOcnIzz58/D1dUVxm96j74vUVFRqFChAq5duwZbW9s8G6O+wvcr5/A9yxl8v3IG3y/t3S+ypEmkq1atClPTrG1mgxPqvOT169ewt7dHZGQk7OzstD0c2cP3K+fwPcsZfL9yBt8v3bhfHEzGMAzDMDKGhZphGIZhZAwLdS6wsLDA2LFjxV/m3fD9yjl8z3IG36+cwfdLN+4Xz1EzDMMwjIxhi5phGIZhZAwLNcMwDMPIGBZqhmEYhpExLNS5YNasWfDy8oKlpSUCAgIQFBSk7SHJlv/++w9t27aFu7s7jIyMsHnzZm0PSbZMmjQJNWrUEAUVihQpgg4dOuDmzZvaHpZsmT17NipXrizyWmmpXbs2du7cqe1h6QyTJ08W/ye//PJLbQ9FtowbN07cI/WlXLlyBXZ9Fur3ZM2aNRgxYoSIADx37hz8/PzQvHlzPHv2TNtDkyUxMTHiHtHDDZM1hw8fxmeffYaTJ09i7969SEpKQrNmzcQ9ZN7Gw8NDiM3Zs2dx5swZNGrUCO3bt8fVq1e1PTTZc/r0acydO1c86DBZ4+vrK+pzK5ejR4+iwKCobybn1KxZU/HZZ5+ptlNSUhTu7u6KSZMmaXVcugB97TZt2qTtYegMz549E/fs8OHD2h6KzuDo6KhYsGCBtocha6KiohSlS5dW7N27V9GgQQPF8OHDtT0k2TJ27FiFn5+f1q7PFvV7kJiYKJ7emzRpotpHdcNp+8SJE1odG6N/ULlCwsnJSdtDkT0pKSlYvXq18D6QC5zJHPLatG7dWuN3jMmc27dvi6k7Hx8f9OjRAw8fPkRBYXDds/KC58+fix8EauyhDm3fuHFDa+Ni9A8q3E9zh3Xr1kXFihW1PRzZcvnyZSHM8fHxKFSoEDZt2iSaJzAZQw8zNGVHrm/m3VAM0pIlS1C2bFnh9h4/fjzq16+PK1euFEgzExZqhpG51UM/BgU6H6aD0A/ohQsXhPdh/fr1CAwMFHP9LNZvExISguHDh4v4BwqEZd5Ny5YtVes0n0/CXaJECaxduxb9+/dHfsNC/R64uLjAxMRE1dtaCW27ublpbVyMfvH5559j27ZtImKeAqaYzDE3N0epUqXEevXq1YWl+Oeff4pAKUYTmrajoNdq1aqp9pGHkL5nM2fOREJCgvh9YzLHwcEBZcqUwZ07d1AQ8Bz1e/4o0I/B/v37NVyUtM3zYkxuoXg7Emly3x44cADe3t7aHpLOQf8fSXCYt2ncuLGYKiAPhHLx9/cX8660ziL9bqKjo3H37l0ULVoUBQFb1O8JpWaRe42+4DVr1sT06dNFAEvfvn21PTTZfrHVnz7v378vfhQoQMrT01OrY5Oju3vlypX4999/xfxXaGio2E99cK2srLQ9PNkxevRo4Zqk71FUVJS4d4cOHcLu3bu1PTRZQt+p9PEONjY2cHZ25jiITBg1apSoA0Hu7idPnoi0XHqg6d69OwoCFur3pFu3bggPD8eYMWPED2mVKlWwa9eutwLMGAnKb23YsKHGgw5BDzsUpMFoFvAgPvzwQ439ixcvRp8+fbQ0KvlCbtzevXuLIB96mKE5RBLppk2bantojJ7w6NEjIcovXrxA4cKFUa9ePVHngNYLAu6exTAMwzAyhueoGYZhGEbGsFAzDMMwjIxhoWYYhmEYGcNCzTAMwzAyhoWaYRiGYWQMCzXDMAzDyBgWaoZhGIaRMSzUDMMwDCNjWKgZhsk3jIyMsHnzZm0Pg2F0GhZqhtFTqNwoCWX6pUWLFtoeGsMwOYBrfTOMHkOiTDXC1bGwsNDaeBiGyTlsUTOMHkOiTD3S1RdHR0fxGlnX1ACEOk9RVy4fHx+sX79e4/3UDrFRo0bidequNGjQINEJTZ1FixbB19dXXIva/lGLTnWeP3+Ojh07wtraGqVLl8aWLVtUr7169Uq0V6TmBnQNej39gwXDGDos1AxjwPz444/o1KkTLl68KATz448/xvXr18Vr1La1efPmQthPnz6NdevWYd++fRpCTEJPbTlJwEnUSYRLlSqlcY3x48eja9euuHTpElq1aiWu8/LlS9X1r127hp07d4rr0vlcXFwK+C4wjMyh7lkMw+gfgYGBChMTE4WNjY3GMnHiRPE6/fcfPHiwxnsCAgIUQ4YMEevz5s1TODo6KqKjo1Wvb9++XWFsbKwIDQ0V2+7u7orvv/8+0zHQNX744QfVNp2L9u3cuVNst23bVtG3b988/uQMo1/wHDXD6DHUA1zZ31qJk5OTar127doar9H2hQsXxDpZuH5+frCxsVG9XrduXaSmpuLmzZvCdf7kyRM0btw4yzFQf2gldC47OzvRQ5oYMmSIsOjPnTuHZs2aoUOHDqhTp04uPzXD6Bcs1Ayjx5AwpndF5xU0p5wdzMzMNLZJ4EnsCZoff/DgAXbs2IG9e/cK0SdX+pQpU/JlzAyji/AcNcMYMCdPnnxru3z58mKd/tLcNc1VKzl27BiMjY1RtmxZ2NrawsvLC/v378/VGCiQLDAwEMuXL8f06dMxb968XJ2PYfQNtqgZRo9JSEhAaGioxj5TU1NVwBYFiPn7+6NevXpYsWIFgoKCsHDhQvEaBX2NHTtWiOi4ceMQHh6OYcOGoVevXnB1dRXH0P7BgwejSJEiwjqOiooSYk7HZYcxY8agevXqImqcxrpt2zbVgwLDMBIs1Ayjx+zatUukTKlD1vCNGzdUEdmrV6/G0KFDxXGrVq1ChQoVxGuUTrV7924MHz4cNWrUENs0nzx16lTVuUjE4+PjMW3aNIwaNUo8AHTu3Dnb4zM3N8fo0aMRHBwsXOn169cX42EYJg0jiihT22YYxkCgueJNmzaJAC6GYeQLz1EzDMMwjIxhoWYYhmEYGcNz1AxjoPCsF8PoBmxRMwzDMIyMYaFmGIZhGBnDQs0wDMMwMoaFmmEYhmFkDAs1wzAMw8gYFmqGYRiGkTEs1AzDMAwjY1ioGYZhGEbGsFAzDMMwDOTL/wG0sdfSJG1iGAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {},
   "source": [
    "- Above, based on the downward slope, we see that the model learns well\n",
    "- Furthermore, the fact that the training and validation loss are very close indicates that the model does not tend to overfit the training data\n",
    "- Similarly, we can plot the accuracy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed9b0d",
   "metadata": {},
   "source": [
    "显示了生成的准确率。模型在第四轮和第五轮后达到了相对较高的训练集准确率和验证集准确率。重要的是，我们在使用 train_classifier_simple 函数时将eval_iter 设置为 5，这意味着为了提高训练过程中的效率，训练集和验证集的性能评估仅基于 5 轮。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {},
   "source": [
    "- Based on the accuracy plot above, we can see that the model achieves a relatively high training and validation accuracy after epochs 4 and 5\n",
    "- However, we have to keep in mind that we specified `eval_iter=5` in the training function earlier, which means that we only estimated the training and validation set performances\n",
    "- We can compute the training, validation, and test set performances over the complete dataset as follows below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2472cd94",
   "metadata": {},
   "source": [
    "现在，需要通过运行以下代码来计算整个数据集在训练集、验证集和测试集上的性能指标，这次不用定义 eval_iter 值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.69%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59656d1",
   "metadata": {},
   "source": [
    "训练集和测试集的性能几乎相同。训练集和测试集的准确率的轻微差异表明训练数据的过拟合很小。通常，验证集的准确率会比测试集的准确率稍高，因为模型开发过程中往往会调整超参数以提升在验证集上的性能，这可能导致模型在测试集上并不完全适用。这种情况很常见，但可以通过调整模型设置 [ 比如增加 dropout 率(drop_rate)或优化器配置中的权重衰减参数(weight_decay)] 来尽量缩小这种差距。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {},
   "source": [
    "- We can see that the training and validation set performances are practically identical\n",
    "- However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate\n",
    "- This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {},
   "source": [
    "## 6.8 Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-4.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- Finally, let's use the finetuned GPT model in action\n",
    "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
    "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    # 设置模型为评估模式（禁用dropout等训练专用层）\n",
    "    model.eval()\n",
    "\n",
    "    # 文本预处理：将输入文本编码为token ID序列\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    # 获取模型支持的最大上下文长度（从位置嵌入层维度获取）\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]  # 正确维度应为[0]\n",
    "\n",
    "    # 序列截断：确保不超过模型支持长度或指定最大长度\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # 序列填充：用pad_token填充到指定长度（保持输入尺寸统一）\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    # 创建张量并添加批次维度（模型需要batch形式的输入）\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # 模型推理（禁用梯度计算以提升性能）\n",
    "    with torch.no_grad():\n",
    "        # 获取最后一个输出位置的logits（适用于分类任务）\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    # 获取预测标签（最大logit对应的索引）\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # 将数字标签转换为语义标签（1: 垃圾邮件，其他：非垃圾邮件）\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- Let's try it out on a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- Then, in a new session, we could load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- See the [./gpt_class_finetune.py](./gpt_class_finetune.py) script, a self-contained script for classification finetuning\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
    "- In addition, interested readers can find an introduction to parameter-efficient training with low-rank adaptation (LoRA) in [appendix E](../../appendix-E)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
